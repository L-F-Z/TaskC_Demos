# FROM nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04
FROM nvidia/cuda:11.1.1-cudnn8-devel-ubuntu20.04
LABEL maintainer="Hugging Face"
LABEL repository="transformers"

ENV DEBIAN_FRONTEND=noninteractive

# Modify /etc/apt/sources.list to use PkgCache
RUN total_lines=$(wc -l < /etc/apt/sources.list) && lines_to_keep=$((total_lines - 6)) && head -n $lines_to_keep /etc/apt/sources.list > /etc/apt/sources.list.new
RUN sed -i 's|http://archive.ubuntu.com/ubuntu/|http://192.168.2.25:9081/repository/ubuntu/|g' /etc/apt/sources.list.new
RUN mv /etc/apt/sources.list.new /etc/apt/sources.list

RUN apt update && \
    apt install -y bash \
                   build-essential \
                   git \
                   curl \
                   cmake \
                   vim \
                   ca-certificates \
                   python3 \
                   python3-pip && \
    rm -rf /var/lib/apt/lists

# Modify ~/.pip/pip.conf to use PkgCache
RUN mkdir ~/.pip/; test -f ~/.pip/pip.conf && mv ~/.pip/pip.conf ~/.pip/pip.conf.bak; curl -s -o ~/.pip/pip.conf -m 3 https://raw.githubusercontent.com/brandnewworld/staging/refs/heads/main/pip.conf

RUN python3 -m pip install --no-cache-dir --upgrade pip && \
    python3 -m pip install --no-cache-dir \
    numpy \
    mkl \
    packaging==20.9 \
    datasets==2.0.0 \
    sentencepiece==0.1.91 \
    black==20.8b1 \
    cookiecutter==1.7.2 \
    flake8==3.8.3 \
    flax==0.3.2 \
    fugashi==1.0 \
    importlib_metadata \
    ipadic==1.0.0 \
    isort==5.5.4 \
    jax==0.2.8 \
    unidic==1.0.2 \
    unidic_lite==1.0.7 \
    tokenizers==0.10.2

# RUN python3 -m pip install -v --no-cache-dir \
#    torch==1.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

# To Manually Install Wheel
RUN python3 -m pip install -v http://192.168.2.25:9081/repository/python/packages/torch/1.9.0%2Bcu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl

# RUN git clone https://github.com/NVIDIA/apex
# RUN cd apex && \
#    python3 setup.py install && \
#    pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./

WORKDIR /workspace

COPY ./LoRA/loralib/ loralib/
COPY ./LoRA/setup.py setup.py
COPY ./LoRA/*.md .
RUN python3 -m pip install --no-cache-dir .

COPY ./LoRA/examples/NLU transformers/

RUN cd transformers/ && \
    python3 -m pip install --no-cache-dir .

CMD ["/bin/bash"]