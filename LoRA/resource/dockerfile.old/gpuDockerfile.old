FROM nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04
LABEL maintainer="Hugging Face"
LABEL repository="transformers"

RUN apt update && \
    apt install -y bash \
                   build-essential \
                   # If install from the Internet
                   # git \
                   curl \
                   ca-certificates \
                   python3 \
                   python3-pip && \
    rm -rf /var/lib/apt/lists

RUN python3 -m pip install --no-cache-dir --upgrade pip && \
    python3 -m pip install --no-cache-dir \
    mkl \
    torch

# RUN python3 -m pip install -v --no-cache-dir \
#    torch==1.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

# To Manually Install Wheel
RUN python3 -m pip install -v http://192.168.143.41:9081/repository/python/packages/torch/1.9.0%2Bcu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl

# RUN git clone https://github.com/NVIDIA/apex
# RUN cd apex && \
#    python3 setup.py install && \
#    pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./


WORKDIR /workspace
# If install from the Internet 
# Run git clone https://github.com/microsoft/LoRA.git && cd LoRA

# Else from local storage
COPY ./LoRA/loralib/ loralib/
COPY ./LoRA/setup.py setup.py
COPY ./LoRA/*.md .

RUN python3 -m pip install --no-cache-dir .

COPY ./LoRA/examples/NLU transformers/

RUN cd transformers/ && \
    python3 -m pip install --no-cache-dir .

CMD ["/bin/bash"]
